{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjkaNahFxcsA"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "from accelerate import infer_auto_device_map, dispatch_model\n",
    "from datasets import load_from_disk, load_metric\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "from google.colab import drive, userdata\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpbXhTGTBV9j"
   },
   "outputs": [],
   "source": [
    "# !pip install evaluate\n",
    "# !pip install sentence_transformers\n",
    "# !pip install bert_score\n",
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iehqaveRYk2Z"
   },
   "outputs": [],
   "source": [
    "hf_token = userdata.get('HF_TOKEN')\n",
    "\n",
    "# Now you can use hf_token to log in:\n",
    "from huggingface_hub import login\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su8lTHrlBV9l"
   },
   "source": [
    "### Loading model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b96836e26087457dba3ca4ebb6a7ddfa",
      "7f40dc830e664a44bea672b873f696aa",
      "51575fee8ffe48b7b083b8fdf7dd779d",
      "2c6447a67bf14bec8909865bbfb2acdb",
      "1a0985f348f946fb96057f0fb276784e",
      "e056d74f8d3b4014a05ac2417bf7c18a",
      "e34f86f124c1444ba6726254a2dd7319",
      "b5eaf96c33d5486d9bfda2549a1e55b7",
      "3d961e9cac2f4661a0fd38e5559fcaa4",
      "47cb04e6ad064151b6cff12f5a68891c",
      "a4b13ee8395c48f39fc5d3ad997dc4ea"
     ]
    },
    "id": "CH4bW8-ux11d",
    "outputId": "91f2a44a-6f0d-4939-fb82-5d8c2396fbe6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96836e26087457dba3ca4ebb6a7ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "offload_dir = \"/content/drive/My Drive/Digital-Self-Replica/offload\"\n",
    "adapter_path = \"/content/drive/My Drive/Digital-Self-Replica/francesco_lora/checkpoint_600\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# loading model on CPU first for mapping\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=None,\n",
    "    low_cpu_mem_usage=True,\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "# get device map\n",
    "device_map = infer_auto_device_map(\n",
    "    base_model,\n",
    "    max_memory={0: \"15GiB\", \"cpu\": \"28GiB\"},\n",
    ")\n",
    "\n",
    "# dispatch\n",
    "base_model = dispatch_model(base_model, device_map=device_map, offload_dir=offload_dir)\n",
    "\n",
    "# loading LoRA adapter\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b96836e26087457dba3ca4ebb6a7ddfa",
      "7f40dc830e664a44bea672b873f696aa",
      "51575fee8ffe48b7b083b8fdf7dd779d",
      "2c6447a67bf14bec8909865bbfb2acdb",
      "1a0985f348f946fb96057f0fb276784e",
      "e056d74f8d3b4014a05ac2417bf7c18a",
      "e34f86f124c1444ba6726254a2dd7319",
      "b5eaf96c33d5486d9bfda2549a1e55b7",
      "3d961e9cac2f4661a0fd38e5559fcaa4",
      "47cb04e6ad064151b6cff12f5a68891c",
      "a4b13ee8395c48f39fc5d3ad997dc4ea"
     ]
    },
    "id": "CH4bW8-ux11d",
    "outputId": "91f2a44a-6f0d-4939-fb82-5d8c2396fbe6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96836e26087457dba3ca4ebb6a7ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "offload_dir = \"/content/drive/My Drive/Digital-Self-Replica/offload\"\n",
    "adapter_path = \"/content/drive/My Drive/Digital-Self-Replica/francesco_lora/checkpoint_600\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# loading model on CPU first for mapping\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=None,\n",
    "    low_cpu_mem_usage=True,\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "# get device map\n",
    "device_map = infer_auto_device_map(\n",
    "    base_model,\n",
    "    max_memory={0: \"15GiB\", \"cpu\": \"28GiB\"},\n",
    ")\n",
    "\n",
    "# dispatch\n",
    "base_model = dispatch_model(base_model, device_map=device_map, offload_dir=offload_dir)\n",
    "\n",
    "# loading LoRA adapter\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b96836e26087457dba3ca4ebb6a7ddfa",
      "7f40dc830e664a44bea672b873f696aa",
      "51575fee8ffe48b7b083b8fdf7dd779d",
      "2c6447a67bf14bec8909865bbfb2acdb",
      "1a0985f348f946fb96057f0fb276784e",
      "e056d74f8d3b4014a05ac2417bf7c18a",
      "e34f86f124c1444ba6726254a2dd7319",
      "b5eaf96c33d5486d9bfda2549a1e55b7",
      "3d961e9cac2f4661a0fd38e5559fcaa4",
      "47cb04e6ad064151b6cff12f5a68891c",
      "a4b13ee8395c48f39fc5d3ad997dc4ea"
     ]
    },
    "id": "CH4bW8-ux11d",
    "outputId": "91f2a44a-6f0d-4939-fb82-5d8c2396fbe6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96836e26087457dba3ca4ebb6a7ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "offload_dir = \"/content/drive/My Drive/Digital-Self-Replica/offload\"\n",
    "adapter_path = \"/content/drive/My Drive/Digital-Self-Replica/francesco_lora/checkpoint_600\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# loading model on CPU first for mapping\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=None,\n",
    "    low_cpu_mem_usage=True,\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "# get device map\n",
    "device_map = infer_auto_device_map(\n",
    "    base_model,\n",
    "    max_memory={0: \"15GiB\", \"cpu\": \"28GiB\"},\n",
    ")\n",
    "\n",
    "# dispatch\n",
    "base_model = dispatch_model(base_model, device_map=device_map, offload_dir=offload_dir)\n",
    "\n",
    "# loading LoRA adapter\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b96836e26087457dba3ca4ebb6a7ddfa",
      "7f40dc830e664a44bea672b873f696aa",
      "51575fee8ffe48b7b083b8fdf7dd779d",
      "2c6447a67bf14bec8909865bbfb2acdb",
      "1a0985f348f946fb96057f0fb276784e",
      "e056d74f8d3b4014a05ac2417bf7c18a",
      "e34f86f124c1444ba6726254a2dd7319",
      "b5eaf96c33d5486d9bfda2549a1e55b7",
      "3d961e9cac2f4661a0fd38e5559fcaa4",
      "47cb04e6ad064151b6cff12f5a68891c",
      "a4b13ee8395c48f39fc5d3ad997dc4ea"
     ]
    },
    "id": "CH4bW8-ux11d",
    "outputId": "91f2a44a-6f0d-4939-fb82-5d8c2396fbe6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96836e26087457dba3ca4ebb6a7ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "offload_dir = \"/content/drive/My Drive/Digital-Self-Replica/offload\"\n",
    "adapter_path = \"/content/drive/My Drive/Digital-Self-Replica/francesco_lora/checkpoint_600\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# loading model on CPU first for mapping\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=None,\n",
    "    low_cpu_mem_usage=True,\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "# get device map\n",
    "device_map = infer_auto_device_map(\n",
    "    base_model,\n",
    "    max_memory={0: \"15GiB\", \"cpu\": \"28GiB\"},\n",
    ")\n",
    "\n",
    "# dispatch\n",
    "base_model = dispatch_model(base_model, device_map=device_map, offload_dir=offload_dir)\n",
    "\n",
    "# loading LoRA adapter\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmWrYYmSyGL4",
    "outputId": "959cfe2f-88aa-4d96-e1bd-23ff1aaa80a9"
   },
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx], dtype=torch.long),\n",
    "            \"labels\": torch.tensor(self.encodings[\"labels\"][idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "tokenized_test = load_from_disk('/content/drive/MyDrive/Digital-Self-Replica/datasets/tokenized_test')\n",
    "#tokenized_test = load_from_disk('./datasets/tokenized_test')\n",
    "\n",
    "test_dataloader = ChatDataset(tokenized_test)\n",
    "test_dataloader = DataLoader(test_dataloader, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtokA7v1BV9q"
   },
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flkeiwLjyjrG"
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, dataset, tokenizer, device=\"cuda\"):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_tokens_in_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataset, desc=\"Calculating Perplexity\")):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            num_tokens = (labels != -100).sum().item()\n",
    "\n",
    "            if num_tokens == 0:\n",
    "                continue\n",
    "\n",
    "            # report metrics only if there is a response\n",
    "            if num_tokens > 0:\n",
    "                total_loss += loss.item() * num_tokens\n",
    "                total_tokens_in_loss += num_tokens\n",
    "\n",
    "    avg_loss = total_loss / total_tokens_in_loss\n",
    "    perplexity = torch.exp(torch.tensor(avg_loss, device=device))\n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e874g2Ncj3Bn",
    "outputId": "e796e5f3-8167-4f9e-d0f3-6140be7cdf89"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████| 69/69 [12:14<00:00, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Fine-Tuned Model with rank = 16: 28.44940185546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perplexity = calculate_perplexity(finetuned_model, test_dataloader, tokenizer)\n",
    "print(f\"Perplexity of Fine-Tuned Model with rank = 16: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EznTS6Vyp_nI",
    "outputId": "b305da47-a367-437a-8e61-e44d3114c94e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████| 69/69 [12:09<00:00, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Fine-Tuned Model with rank = 32: 27.985580444335938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perplexity = calculate_perplexity(finetuned_model, test_dataloader, tokenizer)\n",
    "print(f\"Perplexity of Fine-Tuned Model with rank = 32: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qt3PfcBdolHo",
    "outputId": "22c682b4-0de4-4edd-f097-f5b89a08cc71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████| 69/69 [11:06<00:00,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Base Model: 9286.6884765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perplexity = calculate_perplexity(base_model, test_dataloader, tokenizer)\n",
    "print(f\"Perplexity of Base Model: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gy-rLbOTfzGF",
    "outputId": "0523f2e6-35a0-413d-fd3c-6c6663eb13a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████| 69/69 [11:56<00:00, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Fine-Tuned Model with rank = 64: 31.331012725830078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perplexity = calculate_perplexity(finetuned_model, test_dataloader, tokenizer)\n",
    "print(f\"Perplexity of Fine-Tuned Model with rank = 64 and alpha = 128: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adoGVcwiu-9R",
    "outputId": "68b9b569-f128-425e-e729-5aab7189fd5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████| 69/69 [12:04<00:00, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Fine-Tuned Model with rank = 64 and alpha = 64: 31.680635452270508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perplexity = calculate_perplexity(finetuned_model, test_dataloader, tokenizer)\n",
    "print(f\"Perplexity of Fine-Tuned Model with rank = 64 and alpha = 64: {perplexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVazjmq0nnhk"
   },
   "source": [
    "#### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTpkvnDGDROu",
    "outputId": "80ac37e4-88ae-488c-ef1a-4258f8806621"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Perplexity: 100%|██████████| 69/69 [12:33<00:00, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Fine-Tuned Final Model with rank = 64 and alpha = 32: 17.99485206604004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perplexity = calculate_perplexity(finetuned_model, test_dataloader, tokenizer)\n",
    "print(f\"Perplexity of Fine-Tuned Final Model with rank = 64 and alpha = 32: {perplexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpGWJ0ccBV9s"
   },
   "source": [
    "### Generation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtB9STPUATLl"
   },
   "outputs": [],
   "source": [
    "# pad sequences to same length on the left\n",
    "def left_pad(sequences, pad_value):\n",
    "    max_len = max(seq.size(0) for seq in sequences)\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        pad_len = max_len - seq.size(0)\n",
    "        padded_seq = torch.cat([torch.full((pad_len,), pad_value, dtype=seq.dtype, device=seq.device), seq])\n",
    "        padded.append(padded_seq)\n",
    "    return torch.stack(padded)\n",
    "\n",
    "\n",
    "\n",
    "def convert_label_to_string(label, tokenizer, skip_special_tokens=True):\n",
    "    valid_token_ids = label[label != -100]\n",
    "    token_list = valid_token_ids.tolist()\n",
    "    text = tokenizer.decode(token_list, skip_special_tokens=skip_special_tokens)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# function to print N prompts, responses and ground truths, given a batch of prompts, responses, and ground truths\n",
    "def print_batch_debug(batch_prompts, responses, ground_truths, tokenizer, N=3):\n",
    "\n",
    "    # Number of examples to print\n",
    "    to_print = min(N, len(batch_prompts))\n",
    "    for idx in range(to_print):\n",
    "        # decode prompt\n",
    "        prompt_ids = batch_prompts[idx].tolist()\n",
    "        prompt_txt = tokenizer.decode(prompt_ids, skip_special_tokens=True)\n",
    "\n",
    "        # decode predictions\n",
    "        gen_ids = responses[idx].tolist()\n",
    "        gen_txt = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "        # ground truths\n",
    "        gt_txt = ground_truths[idx]\n",
    "\n",
    "        print(f\"{'-'*10} Example {idx+1} {'-'*10}\")\n",
    "        print(f\"Prompt:\\n{prompt_txt}\")\n",
    "        print(f\"\\nGenerated:    {gen_txt}\")\n",
    "        print(f\"Ground Truth: {gt_txt}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "# function to print prompts, responses, and ground truths\n",
    "def analyze_generation(model, dataset, tokenizer, device=\"cuda\", print_every=10):\n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(dataset, desc=\"Generation: \")):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        ground_truths = []\n",
    "        for label in labels:\n",
    "            gt_txt = convert_label_to_string(label, tokenizer)\n",
    "            ground_truths.append(gt_txt)\n",
    "\n",
    "        batch_prompts = []\n",
    "        for i in range(input_ids.size(0)):\n",
    "            prompt_tokens = input_ids[i][labels[i] == -100]\n",
    "            batch_prompts.append(prompt_tokens)\n",
    "\n",
    "        pad_token_id = tokenizer.pad_token_id\n",
    "        padded_prompts = left_pad(batch_prompts, pad_token_id).to(device)\n",
    "\n",
    "\n",
    "        # generating responses\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(\n",
    "                input_ids=padded_prompts,\n",
    "                attention_mask=(padded_prompts != pad_token_id).long(),\n",
    "                max_new_tokens=90,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=pad_token_id,\n",
    "                do_sample=True,\n",
    "                top_p=0.95,\n",
    "                temperature=0.4,\n",
    "                num_return_sequences=1\n",
    "            )\n",
    "\n",
    "\n",
    "        # remove prompt to get only responses\n",
    "        responses = []\n",
    "        for gen, prompt in zip(generated, padded_prompts):\n",
    "            gen_response = gen[len(prompt):]  # Slice off the prompt part\n",
    "            responses.append(gen_response)\n",
    "\n",
    "        # decoded_responses = [tokenizer.decode(r, skip_special_tokens=True) for r in responses]\n",
    "        #print(decoded_responses)\n",
    "        # input_ids_not_padded = [torch.cat([prompt, response]) for prompt, response in zip(padded_prompts, responses)]\n",
    "        # input_ids = left_pad(input_ids_not_padded, pad_token_id).to(device)\n",
    "\n",
    "        #decoded_inputs = [tokenizer.decode(input, skip_special_tokens=False) for input in input_ids]\n",
    "        #print(decoded_inputs)\n",
    "\n",
    "        attention_mask = (input_ids != pad_token_id).long()\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "\n",
    "        if (batch_idx + 1) % print_every == 0:\n",
    "            print_batch_debug(padded_prompts, responses, ground_truths, tokenizer, N=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTy8X7QzBV9t"
   },
   "source": [
    "### Actual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6hUgJ11BV9t"
   },
   "outputs": [],
   "source": [
    "def evaluate_chat_model(model, tokenizer, dataloader, device=None):\n",
    "    \"\"\"\n",
    "    First we loop for generating the predictions\n",
    "    After that, we measure everything in one shot to speed up process.\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    meteor = load(\"meteor\")\n",
    "    bertscore = load(\"bertscore\")\n",
    "\n",
    "\n",
    "    semantic_model = SentenceTransformer(\n",
    "        'nickprock/sentence-bert-base-italian-uncased',\n",
    "        device='cpu'    # cuda already full\n",
    "    )\n",
    "\n",
    "    all_prompts:    list[str] = []\n",
    "    all_preds:      list[str] = []\n",
    "    all_references: list[str] = []\n",
    "\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    # generation loop: collecting predictions\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating & Collecting\"):\n",
    "            input_ids = batch['input_ids'].to(device)            # (B, seq_len)\n",
    "            labels    = batch['labels'].to(device)               # (B, seq_len)\n",
    "\n",
    "            batch_prompts_ids = []\n",
    "            for i in range(input_ids.size(0)):\n",
    "                mask = labels[i] == -100\n",
    "                prompt_ids = input_ids[i][mask]\n",
    "                batch_prompts_ids.append(prompt_ids)\n",
    "\n",
    "            padded_prompts = left_pad(batch_prompts_ids, pad_token_id).to(device)\n",
    "\n",
    "            prompts_text = tokenizer.batch_decode(\n",
    "                padded_prompts, skip_special_tokens=True\n",
    "            )\n",
    "            all_prompts.extend(prompts_text)\n",
    "\n",
    "\n",
    "            ground_truths = [\n",
    "                convert_label_to_string(label, tokenizer)\n",
    "                for label in labels\n",
    "            ]\n",
    "            all_references.extend(ground_truths)\n",
    "\n",
    "            generated = model.generate(\n",
    "                input_ids=padded_prompts,\n",
    "                attention_mask=(padded_prompts != pad_token_id).long(),\n",
    "                max_new_tokens=90,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=pad_token_id,\n",
    "                do_sample=True,\n",
    "                top_p=0.95,\n",
    "                temperature=0.4,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=False\n",
    "            )\n",
    "\n",
    "            sequences = generated.sequences\n",
    "            gen_tokens = sequences[:, padded_prompts.size(1):]    # only response part\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                gen_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            all_preds.extend(decoded_preds)\n",
    "\n",
    "    # lists built\n",
    "\n",
    "    # meteor score\n",
    "    meteor_res = meteor.compute(\n",
    "        predictions=all_preds,\n",
    "        references=all_references\n",
    "    )\n",
    "    avg_meteor = meteor_res[\"meteor\"]\n",
    "\n",
    "    # BERTScore\n",
    "    bert_res = bertscore.compute(\n",
    "        predictions=all_preds,\n",
    "        references=all_references,\n",
    "        lang=\"it\",\n",
    "        model_type=\"dbmdz/bert-base-italian-xxl-cased\",\n",
    "        num_layers=12,\n",
    "        device=\"cpu\",\n",
    "        batch_size=16,\n",
    "        rescale_with_baseline=False\n",
    "    )\n",
    "    avg_bertscore_f1 = float(np.mean(bert_res[\"f1\"]))\n",
    "\n",
    "    # Semantic Similarity\n",
    "    prompt_embeds = semantic_model.encode(\n",
    "        all_prompts,\n",
    "        convert_to_tensor=True,\n",
    "        normalize_embeddings=True,\n",
    "        batch_size=64,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    pred_embeds = semantic_model.encode(\n",
    "        all_preds,\n",
    "        convert_to_tensor=True,\n",
    "        normalize_embeddings=True,\n",
    "        batch_size=64,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    ref_embeds = semantic_model.encode(\n",
    "        all_references,\n",
    "        convert_to_tensor=True,\n",
    "        normalize_embeddings=True,\n",
    "        batch_size=64,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    sim_pred_ref = util.cos_sim(pred_embeds, ref_embeds).diagonal().cpu().numpy()\n",
    "    sim_prompt_pred = util.cos_sim(prompt_embeds, pred_embeds).diagonal().cpu().numpy()\n",
    "    sim_prompt_ref  = util.cos_sim(prompt_embeds, ref_embeds).diagonal().cpu().numpy()\n",
    "\n",
    "    avg_semantic_similarity = float(np.mean(sim_pred_ref))\n",
    "    avg_prompt_pred       = float(np.mean(sim_prompt_pred))\n",
    "    avg_prompt_ref        = float(np.mean(sim_prompt_ref))\n",
    "    prompt_alignment_ratio = avg_prompt_pred / (avg_prompt_ref + 1e-12)\n",
    "\n",
    "    return {\n",
    "        \"meteor\": avg_meteor,\n",
    "        \"bertscore_f1\": avg_bertscore_f1,\n",
    "        \"semantic_similarity\": avg_semantic_similarity,\n",
    "        \"prompt_alignment\": {\n",
    "            \"predicted\": avg_prompt_pred,\n",
    "            \"ground_truth\": avg_prompt_ref,\n",
    "            \"ratio\": prompt_alignment_ratio\n",
    "        },\n",
    "        \"predictions\": all_preds,\n",
    "        \"references\": all_references\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "127bcf7f33b74f63892ba01a3f48ffb8",
      "81ccf3c19b4e4585ab576d3996f92e26",
      "1d6f358fb6f24e808e17dc5639279218",
      "d6ea758e219e4e44b57e845a070a0f57",
      "c8fc48bba18b4e9fab177106fe5a66ee",
      "2992592149014643bb37068366b2c030",
      "5d36d8e89adb4424b19511ae0c5c22e2",
      "67efd7b3e4bb4665b372e7d2ec6f49ea",
      "f662815d94994b57b9a7cdea8c760dca",
      "c35ae2d052c745989d0baf99e8457bb3",
      "26d2537675a846bba232b5fd3ba7ea1a",
      "e8f17a2516a94876abe37995099924b5",
      "e0d59c12150448e68c835d5fd9ec2c80",
      "b4f28e4236c44314aac4b379b0d681c9",
      "024a6adbe226477d9c94a3bbe19b59a2",
      "810fbd2a3f2341598a811a627614db35",
      "c19dea7992824ef4896aa52ba81feada",
      "a32b5a5285c846ad8cb9cb3acd14e566",
      "fa5752d60153496e86c0fcbadec6bb26",
      "8ad553da7f294bf59da6cb6b10128e19",
      "8eb58365fb3648a7aae2d933266ce94d",
      "bb9849fbc2444360a4530ab072ef4297",
      "5e7e93a234a340d1bb13e52ea1cb811b",
      "bd62daa8bce44c6b978447656087e83d",
      "e9cc510d366440e185e705b7db1e7297",
      "5971540fe78947a59c908a1002a2178a",
      "0c58329bbcf2439c8e2970b6ff9236e1",
      "f3e1763e59e94482b4f189e2b827b8d6",
      "2e5b4d2bb1354eacadb2dbb2e92a11c4",
      "75fac6526981495f9c18793ae42300e3",
      "e62aaf1f4603409eb4901695f0cdc84c",
      "446c68edc3f447e9bda2ddb7722cbb94",
      "9b9b96266a8341979d5e5da9c1e89fca"
     ]
    },
    "id": "_xLXI20l5-Eb",
    "outputId": "c08ff248-71f5-41e0-9833-35b5fe495a43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Generating & Collecting: 100%|██████████| 69/69 [21:14<00:00, 18.47s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127bcf7f33b74f63892ba01a3f48ffb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f17a2516a94876abe37995099924b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7e93a234a340d1bb13e52ea1cb811b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Baseline Evaluation Results:\n",
      "    - METEOR: 0.011 (0-1, higher=better)\n",
      "    - BERTScore F1: 0.275 (0-1, higher=better)\n",
      "    - Semantic Similarity: 0.220 (0-1 cosine)\n",
      "    Prompt Alignment:\n",
      "    - Model Responses: 0.638\n",
      "    - Ground Truth: 0.245\n",
      "    - Alignment Ratio: 260.8%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_chat_model(base_model, tokenizer, test_dataloader)\n",
    "\n",
    "print(f\"\"\"\n",
    "    Baseline Evaluation Results:\n",
    "    - METEOR: {results['meteor']:.3f} (0-1, higher=better)\n",
    "    - BERTScore F1: {results['bertscore_f1']:.3f} (0-1, higher=better)\n",
    "    - Semantic Similarity: {results['semantic_similarity']:.3f} (0-1 cosine)\n",
    "    Prompt Alignment:\n",
    "    - Model Responses: {results['prompt_alignment']['predicted']:.3f}\n",
    "    - Ground Truth: {results['prompt_alignment']['ground_truth']:.3f}\n",
    "    - Alignment Ratio: {results['prompt_alignment']['ratio']:.1%}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "d24fe75291f54dae9b0c25fd634ed881",
      "8627ad4b67a74462a3816d456d097df7",
      "d83ada485ad94743bf7d197e495c76fd",
      "104350039d9f43adbaafd35386e28af1",
      "7e78f85b216b469f91ccf7eafc667f17",
      "11c89db18f044f108277472dd792922d",
      "f3f2ffcfe7074a4cbd73210e5ab43473",
      "4c8127fe76e64501951028953938b77a",
      "68f203ce3b004461815be3931fda50e3",
      "2288571adabb4785bb2afaa6ffa5008e",
      "253780ee3e494127813b5e207c53a5c3",
      "998b6025024e423b87bea598d165df3c",
      "24e53d1b321044cdaf1be828b5e63020",
      "cb12ff6e835a40b19f33367a2c074ecb",
      "0ab3fb4755744a9ba6e6bae2cfdcdec2",
      "ce0f4f565c7241c5b1b4183ed4e14299",
      "c2bdc47251ed4a2a8f3a04808a47483d",
      "e82f7d86b84b4a07a9b4aebfef04c90c",
      "3b807d2f2dbc49f4bac7243da6002aa4",
      "fb66322e2aef49f9bad5ecd6f3cd33bd",
      "8c3148911e7d4c3f9d95428b25ed3e4d",
      "c5c3928b8a2c409db1159f6836cb4d6c",
      "37a46ee0ed2b43adac2bef4dfb7db6e2",
      "6aae9bcc2d5a4bdd913edfdb1d33125f",
      "446a1f4e90454bdbb30855b6afa0cffa",
      "4eb73f3fa0864d469e9f33e1fce0f3a2",
      "f5b2dd60612f42a0a70e131cde811bbf",
      "51183f1bfe9046f3a307f34f02d7a9ac",
      "16a8cc486e74431fba898e21752ecd63",
      "53c50225b63d42bb8b2ec19ec42cd706",
      "d9ce3bbd88164a6db2cb9dc9d169a72f",
      "4c1d11af10f048b0b90984be714d2730",
      "34c6322e52334ea192a536f817eadabd"
     ]
    },
    "id": "vwA3Cuko5xTa",
    "outputId": "2ffce79f-c210-4523-e0a3-f2377590e922"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Generating & Collecting: 100%|██████████| 69/69 [17:26<00:00, 15.17s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24fe75291f54dae9b0c25fd634ed881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998b6025024e423b87bea598d165df3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a46ee0ed2b43adac2bef4dfb7db6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Finetuned model with r=32 Evaluation Results:\n",
      "    - METEOR: 0.027 (0-1, higher=better)\n",
      "    - BERTScore F1: 0.409 (0-1, higher=better)\n",
      "    - Semantic Similarity: 0.281 (0-1 cosine)\n",
      "    Prompt Alignment:\n",
      "    - Model Responses: 0.251\n",
      "    - Ground Truth: 0.245\n",
      "    - Alignment Ratio: 102.7%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_chat_model(finetuned_model, tokenizer, test_dataloader)\n",
    "\n",
    "print(f\"\"\"\n",
    "    Finetuned model with r=32 Evaluation Results:\n",
    "    - METEOR: {results['meteor']:.3f} (0-1, higher=better)\n",
    "    - BERTScore F1: {results['bertscore_f1']:.3f} (0-1, higher=better)\n",
    "    - Semantic Similarity: {results['semantic_similarity']:.3f} (0-1 cosine)\n",
    "    Prompt Alignment:\n",
    "    - Model Responses: {results['prompt_alignment']['predicted']:.3f}\n",
    "    - Ground Truth: {results['prompt_alignment']['ground_truth']:.3f}\n",
    "    - Alignment Ratio: {results['prompt_alignment']['ratio']:.1%}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615,
     "referenced_widgets": [
      "2543dce3c4ed43138dfd7061aec63b65",
      "338ef9fe7f5747c0867e45a85d1ea297",
      "5d6c778cde014b8bbc2c9df9cb8c858f",
      "4ef81498e3cd459fbd8bc71ad4306a93",
      "e599345b9c114c65a8d4d1dede946671",
      "bfd35d6bbda7475a99ce4e5631e29362",
      "0d7cf81f78e24a1aa2fc012ca831c341",
      "c17fbf94627a45ddb465e989e9b68992",
      "ec693accb7f948edafd86afb02d6c9b5",
      "85ad1c2f204a482d82842fa4ce82b000",
      "89503181f6fc42ec8d28a0b2b019b080",
      "e5b8dbdb917f4500a7f4351474897b5d",
      "02f787efbc4540cc9de787604e7b9156",
      "b4173b3947e54a5d9582ac3db7d20bad",
      "4f615a144bc54647b3cc03db985312e8",
      "dc1a9e7d7b9e4dd7a1623f5a1e003896",
      "c042cc6b91374d229a06127e6524c8e9",
      "eb8cccfb33e44c7dad1d2ed4d5be013c",
      "846a643dcca94574a28b23d9c61827f6",
      "f9d2a67a8af040409ef96dd508bcb3c7",
      "711ce3e652a849078e1aaa32188aabf7",
      "6e6d8332743d426fa4e436d05ee56484",
      "6886f487288c4c15a823474925aa873a",
      "7cfeb50deaa64a14888d17fa405a484c",
      "1162f08837f64a14b7b28356be3a0aad",
      "766b903d79fe41fca4739610346f2b1c",
      "79ed2cf2ac214ce3938dd18a1a086f96",
      "1b2ac69cb7774697a266c1e514180b03",
      "fd9db99654fd4255bd250b4c3303d202",
      "ee533eb3c8584e089db3dc0a52166ecb",
      "e30e494f08a64f178ad274dbade9ceba",
      "ff1803e133594ac89e28195fa1f8f625",
      "b25425c7f47c40e8900891c047852f91",
      "132f9049edea48e290dfabd65d376d77",
      "636ca5649bc34512b1c466af11c5dc98",
      "d4b5bbceca374086973e623252ac9b78",
      "1eb1c5d9ec84452698c7a3c03c5c7442",
      "4ddacdaad4b64e5d93509d770945c36c",
      "57f2af4e8bb349b0ae1332447a72c685",
      "1265d31940c64431a65eb50b84d55bc2",
      "12dd1e4dce5e460ba0b6b119fac885b1",
      "51b0b32369114153aab93f2ddbd59061",
      "1451af3db06a40539710c234df246c2b",
      "0db3d68fb38d488bb56718351bafeeb2",
      "463f5a63b88e4464b368eeed5c00566c",
      "a623a94b96714c1487b003d5a75d324c",
      "61bd3f9e87ff4f9d94dacc7714e2dd78",
      "b1235b2637034c7a8e33d4ccd759c0ef",
      "d11f465a5b4c4c3282c0ca690de69f71",
      "5af97be25b5d4e08b88819f8162f0dc1",
      "540971f4863f4ed89bb8ac5f09b6ce08",
      "8def4c748dab4d46a91ea11948bb37e4",
      "277caf0586b84548b77a7bd29f8db662",
      "1f7d7049f2f4492aaa3ab6992f84601e",
      "a0661d7684ab434e9e4e4e11eebd778c",
      "2fdaa93a572a4698abccd3b802fb4437",
      "91e0a18dd7aa42449b1d1832de891aeb",
      "6bfa34fde78248ab9b8dbcae1f64d3e2",
      "84b7d9d83de04520be006368cf3356f7",
      "71067bb576c74c74b8f9a6fa34578365",
      "cedf856920394f27b648988ba2609b97",
      "430c26b0d5754ffeab3392d2731abed3",
      "9c1d2f4a83b34eb883a4c4ac28518e74",
      "4fccb92178b04c3cac7fbde2d90e3514",
      "d964e0ddfde0474fb5354d8ba9dd51f4",
      "4d2206cdd7a8486299d97719cb9b5daa",
      "c87312d3e1474fc4967037961f4972bc",
      "e9fa0cd3d7c34792a1cf7cd82dc4e42a",
      "b1536887b23d4387b312d6259a0e792c",
      "9c5b7a3881bf41adbe17fa01e0a84932",
      "4f8cc119718a4071900d42e63339cd75",
      "ac26c53ca8bd4b80aad0d23b946b2a16",
      "b82f0c7ee4b742dc94c5ef9d9e46825b",
      "89a2b20f29e3444292f004efae09a7d7",
      "b2e458dee07841808119a0bb3f60efef",
      "ac29ababba5e44f08ecc8a247e646add",
      "cd981cef656e4551a2127e2469d0a0fc",
      "1d09efd103d94b68a81d32258e4e7eb1",
      "03d6ceb19c6c4afc9fd8c0899d8c9d53",
      "446826b433ef4a7bab040caabcfd2ff7",
      "304c5565a7b7431cb50edba505ac8c28",
      "6436f519e7f348018c7d4737d0382d56",
      "49bd0e77cab548dfb2e482ebca85f028",
      "8f9e659097ad4bf9ab2434bb05a8a907",
      "bd84943ded6d42c988cb897cd4a7b108",
      "5551e27edcca4d2bb461d57452c34b05",
      "cec331e2899c4451a5fb4d2042d335ef",
      "45cf7f95f01b474ebd80c03ad471258c",
      "203f2280f5f04eb2bf95b94f6703aa61",
      "06d79dfd25db4cef9958d4f5d34011cf",
      "0399b0b1fdc240eeb83b2d728038b67d",
      "c9abdfb81f4a4fc2930649cfa4d9d586",
      "d689d8d82c5f4641855c19b4106e4170",
      "51a6db685099425aa7fec0420fb4fffc",
      "67477e2d7df74b9dbf63bc03f4e87973",
      "529878a0c43840009df8856ff1687a74",
      "20c5ef258561485299eee5f784d69ba0",
      "58f521fa06dc442da82348378b54f696",
      "e703211ba4d04fb1b81ecfa213eec7c3"
     ]
    },
    "id": "xKi8ZwjlDpmk",
    "outputId": "f846b7cd-fc0b-477b-e899-9ba3f6269ef2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2543dce3c4ed43138dfd7061aec63b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b8dbdb917f4500a7f4351474897b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating & Collecting: 100%|██████████| 69/69 [16:16<00:00, 14.16s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6886f487288c4c15a823474925aa873a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132f9049edea48e290dfabd65d376d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463f5a63b88e4464b368eeed5c00566c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/235k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdaa93a572a4698abccd3b802fb4437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87312d3e1474fc4967037961f4972bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d09efd103d94b68a81d32258e4e7eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203f2280f5f04eb2bf95b94f6703aa61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Finetuned model with r=16 Evaluation Results:\n",
      "    - METEOR: 0.028 (0-1, higher=better)\n",
      "    - BERTScore F1: 0.421 (0-1, higher=better)\n",
      "    - Semantic Similarity: 0.278 (0-1 cosine)\n",
      "    Prompt Alignment:\n",
      "    - Model Responses: 0.249\n",
      "    - Ground Truth: 0.245\n",
      "    - Alignment Ratio: 102.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_chat_model(finetuned_model, tokenizer, test_dataloader)\n",
    "\n",
    "print(f\"\"\"\n",
    "    Finetuned model with r=16 Evaluation Results:\n",
    "    - METEOR: {results['meteor']:.3f} (0-1, higher=better)\n",
    "    - BERTScore F1: {results['bertscore_f1']:.3f} (0-1, higher=better)\n",
    "    - Semantic Similarity: {results['semantic_similarity']:.3f} (0-1 cosine)\n",
    "    Prompt Alignment:\n",
    "    - Model Responses: {results['prompt_alignment']['predicted']:.3f}\n",
    "    - Ground Truth: {results['prompt_alignment']['ground_truth']:.3f}\n",
    "    - Alignment Ratio: {results['prompt_alignment']['ratio']:.1%}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 930,
     "referenced_widgets": [
      "a50e81dde9e045c089678875b6d16ac6",
      "98f4cb7a78f049eab9e78e7dcf1c4961",
      "b3223b951b7c4a33a4e759d9397b9549",
      "ca6bf94f77bc48a59a5506cd5e501941",
      "ad7c91331ef44f54af3253daac4ecae6",
      "bd1ef2167a9e4c48a25c0dcddafaef40",
      "582a06b77d90485aab96fca188e427b5",
      "3191534879574c65b0b4e7ad99b9b41a",
      "2855c02df24143f4804b20ad168f0b40",
      "3c703a86c868445e96324f537ee4b4f6",
      "4b48d076380c49cb922150df2b14c262",
      "b55c15326eba49e9a7c0456734a1525b",
      "598f479044924314b98464132da8d9c4",
      "dcafd36147f64f2d9eef75f86b337b78",
      "94b670621b1c41b488fe35fb22f115d3",
      "4b0a8b41f13a496a884c533bcba1607c",
      "1fde3cfa65164c0484347ef9916483f4",
      "f205b80ea09b4e7fa76828d0ea1f20e7",
      "235c7abc29af4c53bde532461f6f313c",
      "e663a39de9c14d87a5b74721983a6919",
      "e8ea56149a0e46a2ae7b88580ac1c74a",
      "4532fc7a5b714ba38b89218f105658bd",
      "caefef85532a423aa85d059e816b86be",
      "994c49496d324f538d95f1b1976ef29b",
      "545bc01fc7d84b56ad08ba6dfdaea4b4",
      "67c2737590df4de38522d76b299b7348",
      "415e84185e574fed9d3c1111030b34f3",
      "3bc650fcd45f4c98a7ab9ccbcaa77c0e",
      "6e041d27268f472b83eae6b27625b625",
      "5e03116b52614610af63e7a3aa4bb4b5",
      "b9588ee12dd04668a6b0020d259203ad",
      "dea0dc511f2940d08679719a7cbbd9b9",
      "319d5a1982de4e878f66f0cb7a1cd8de",
      "98f2807604444c3abbbaca44ac4ef801",
      "fb38a6c5a15143529841677dbcf0ebf0",
      "4745ff55a6b0427ebae4945af3568bbb",
      "4133f738a6564570968ecc074785ef84",
      "17a8b6247bf9420799e7bce273cb7e4f",
      "2dabfd6070b44aee936aa918babfe56d",
      "b6e124ca263f44208c48e9b39b6c11aa",
      "364bb9b419d44281b38cc4377992e1cd",
      "2a10409a7eca4c1db8fc428e8f46b1ac",
      "36762dfe301a4a539a01b0f8429127ec",
      "61d7aa2769f64327b97163fa684cb355",
      "23a323afc9cc4c3e8aa4e186251ea7a9",
      "dd529ee8e3d74f7cb01359e09a751dc3",
      "b70458d1101f4dddb181c876731ca230",
      "3c4b317179224fdda3180b37c5383431",
      "5b7c2f8e24d6406f931e173d3c4e7552",
      "9813b1a9cde44e0bb88762e23ea8f1cf",
      "67b648a0159148d4ac5ff10077916b99",
      "f6ed1314d99a4eb196415fdc801cc7a3",
      "cbcfcdfd43304ec68300bd12f053b1a5",
      "83a0303a7503440b840fdc97b8b425eb",
      "6ec21ca28cc842188eae6105c6d74886",
      "f27187d656774449ae644e74e256cedf",
      "c0c569d494df42768c062a7d46c05c2d",
      "eda2f3fc81b540ccb2e1d0a7d46cd46c",
      "e3ebd0f76c364b8689676ac32fd8ba9d",
      "4d25510fd0184658ae2f80b95ffcd058",
      "7db13ab2d89c4bb6b181ecf948689d34",
      "45eac6d7794b43f086639760112c9c60",
      "73a3c627ea6848e2b76ddebdc598dc50",
      "ac704399672a42908e6f9bee7e80a0a2",
      "faedc80124524f559f3125df0d9ca5a2",
      "acf5de7008804061b1d00f2d9eabfca1",
      "3be19782e19544b395dfa6caa2b3c71f",
      "9d3be56500174e32873e0ed08550985e",
      "1c22b178e34d4fbaaff6f70d6168473c",
      "c651f4136ee3467a91e3e74eb53c1268",
      "58ccbeccf5674f209056922ce6c4fcb5",
      "84608cce291d4e858f08733e933808b8",
      "d26f551ba1384b269eabfe5799403a59",
      "805f270d64ed4fb8baab7a571b2614a3",
      "63f92aaf79b9489d96bddb1cd7669009",
      "47c677c592424be9986cba1823c7152e",
      "c86bd054e3214249901bf51fc4b24656",
      "62ed4008f3d4410cb3e948e4374ea051",
      "98fcdcf17da84546ae0be2eb82513233",
      "c29cf5c4d915445b873fe0a64d8e0f9d",
      "7c3d3c5961494c0387f6533a0c2d68d5",
      "c4e5b40557324ca7b1e4733be284e387",
      "0b8912bb3386414da6ece965873a7d0c",
      "0916ed5a9ca54860bcc4cc588978ee06",
      "640c45a514d749cfb419af9c0514cf68",
      "d67c8167a69645cbb2e89795863f568e",
      "987a1da814e4446aae2845d9aef27d90",
      "77ec96313a8c444d921b1e0de34a4e25",
      "e00b0fb3ae9942349474cdddaabc4c22",
      "c8b60c75ced04bea8ee7784952c16293",
      "ec3cff49a0f34d9f86b0256ec873ad4d",
      "65bf1ce2515b45799d335733a774fd1a",
      "8e47131ea0be45b4b4f02f7dbc97a21c",
      "22dcaa2d8a5043a791303146cac5f371",
      "ccc88676560d47bc8be5744db890f402",
      "8ebe3506f740453fb766404bd63e3ea7",
      "af16cd9a43b94a469a360b7e36f1f729",
      "fff7b643005f4f3db6b75a831e92e231",
      "0cddb1c8ef174489a7c55a9a721185dd",
      "45da92c75f9d475080c12cfabdc8b505",
      "86788145ce98445090d7e96a5b26ab21",
      "7e3af74fa2524dc78b6a4df1b6278028",
      "522ec18a94314730b7b8a8627cf39818",
      "5cf9c870a97f41d38b65ca6c8e248bf7",
      "20a87ba982c548d9864a5b9ea9ebcddb",
      "12a10b9a1ca5479d84801e5bff7402ae",
      "de84e01d632243e79953eef3c3ae74a0",
      "c3ce102b65ec41dfb9ad1b8b4f8ec32b",
      "791145be4b51429b8aeb8c9a4746a6f8",
      "d19b7c96190e4874b32429ffc18eddfe",
      "78bff3a7d6114175be06b67ccd7fdc83",
      "ce52f510d9824aac8f215f36621c3fbd",
      "e5e3c4ae62c04ada809ea2524fcc977d",
      "93d9f372d0b84fab9c7658fc91714c3d",
      "2cd0fd4777454dc9af76eef2c0e79e02",
      "b4d367339c4a41f3a4c1beefde91e534",
      "c983a2d07bd44a78b2552a282c4cd93e",
      "4f0750e51f884d438d7bd74fa7052e3f",
      "30546c2fb0834f329e326a50e12e8162",
      "72a3fdba265a49a19f4fdc7612ae27b6",
      "00880529193744b99cbf1972d94f53fc",
      "03c68266f5fa4b57a05e9368d8c3d88a",
      "87c9a8f767404ea6b139b86c88f76a67",
      "be08b3d5e6bf4349adca9befb5d5e93d",
      "d67a916525004281891017114b0f320f",
      "34a6a7209588469098bc4f05918be102",
      "bb80fbcb47164ce9b20df2a71bd910e4",
      "9ea8c18808f048b1a43d043ac6c495b9",
      "cfe29eb75f0e438782ee18d6ef8f1c14",
      "0ae12cdf3dee4b51a66b21c28294edf3",
      "4d7bee6298b94ed490b66922d84c8ab2",
      "3203fdc6ce8b40a087dd1064d7992533",
      "93e81c46a1244ea18c60e9e3555a2175",
      "60b4859d50084eccb357228cb7fb5456",
      "796b2ac9d1e941d199bac2743db593cd",
      "63e92cd38d93476394020dac6af9ce1b",
      "9945b305ec5343f69241e59e8e885279",
      "396a488b7866404c9b1c1afa9c565b19",
      "184fc8da8bfc41d79f9636a115e0c544",
      "43ff3326fcae46bbb29b841078e75f5b",
      "241d1f7a81c54f5a9466d77c5cc27a78",
      "6ed86580bc234684ad5e2b9f4aa3e97c",
      "a7c46330a87947c7865f692534a0676a",
      "643b33938a5e446ba8584400ec6440ce",
      "72100d98485b4c2e8fb950e83b72efe3",
      "187afb0b784045c9a5a2ef68eff97751",
      "c61a8622fff2447ea49aa698442ab9df",
      "57afbd7203b94d39bee7b615a5f3f43b",
      "95956453e1ef459a87416ef6237ff0ee",
      "3d5068869f5d4390b16f816ca6f728dc",
      "6b658a3fb9404becb8f5b01b32b93b5d",
      "87e63d78923a44099bc0761a8c6d2518",
      "f61ea3c39bf5492cbbe332e4bf3b917b",
      "ec59157c1a1245f09289a7bd18e72d9a",
      "15ec62bad87b4775841af125557f7478",
      "eddefb8b984d438f80ac557f1ee3d686",
      "4d76ebe6eb9540fbac23839fd18ce0de",
      "3b67b5b7567a47f6b55a1d3814889c0e",
      "8e1e28539b1745b892b86b5e47b67165",
      "fe1678bd7ca9468f92ff09d83d232a3e",
      "3e64e4f1bbb74124868707c50363987f",
      "c522a35c6e1b4c23a004d163dc30a089",
      "36b2669414364cb38872e79045ed3cfa",
      "9d161204f8ed4ab39c616fb8a10f8235",
      "57b28ec1e55e42838d634cbb5428b015",
      "2e76211d207d45b39511fc7111f302a6",
      "a9c99f63e4a743fbaf37459e17f7e30b",
      "ef796e441ec649ffbeb76a3c6d31f72c",
      "d2ed72548a1049639d356a4e89da4486",
      "dd20cc36d142430d9a1cdfe79e6c96fd",
      "be65720ed7234c03bcc6ea12161f1563",
      "6794907835474a7dbca9c29af1e63a68",
      "d2fcab7736ad445099b41e7572424126",
      "d941671648774e75895e3a24f07d2cb0",
      "0e69eaf30ea1464e94fd3f18995b1cc0",
      "b5bd243b11974296b95e49e74f47ed9e",
      "cc1b285566d1459eb172444419b80ed7",
      "0bb13cf1953a452c8955b3523d54e189",
      "ec5c1b7ad6cf43629b9f9ce85abfc280",
      "a00addb79b8d4788b031ea0cb4808fd9",
      "5974e48d062b4b70abdd13bfb01e9bde",
      "5afb55b492c443d0b5f9cc592343cef1",
      "ff95cfbde17c486eb40ccccd4ed325e2",
      "ff19c165ffad4596b37a6e0463f8b871",
      "ebe4e2723659435fb31cc552c98840f5",
      "f5d9b38748634795866abe624cf21204",
      "649cfe7f0c7546f3a25dad6e7f4282ef",
      "02b32dae3d7a4f32af1d97db851f7c2b",
      "a398130e44c5495b83f5f661332509b1",
      "695ebb7fd3dc4f108c1c4fbf1c6adb9d",
      "38d9cf59d07540cd9d7003f5c5c17fa0",
      "eab2238fb9f4469aa296fcfda73a66e2",
      "d2855e2a9d0b41d2a30648410a0858d0",
      "3ffc4e357ce049f588216e94cd3fb765",
      "84b372d3deee41e2aae3fad617e53fe8",
      "2b151dca39084a1cbe264c55833de837",
      "c8c99fc60b51467d8185ed693e522ef9",
      "6a1f5b9a2084498fa6837cedb81a804f",
      "ac98b496fe1a47a9a2f482f8db16cceb",
      "dae50926d7944d42b4bebe8e8c476467",
      "e6c4a012b4bc4ae590456be2ae652f72",
      "d3fd6de0680a4598b5786c69b423fb27",
      "bd42f19f9c764d72b9dc31efb24034a5",
      "846d8caaa7f54582b5c3383339fbe4c2",
      "b5796eb7f4a24ee49c1bccffbcbf6e19",
      "f325bb99b32f419a86f627ee75c83fad",
      "fcd25751ce644508810385bf40fe615f",
      "933d003826474c1d91ca58858da0b2c1",
      "04833add2f3e449a8de067a5f9c9068c",
      "0f97aacd10c04cf7bcea22035d49b3d4",
      "b35c4b363a0d450a96356e851996579b",
      "590c33854f9d428a876e68d053324122",
      "f906471ae9054e038a1d44251db5014c",
      "25457235bc944b819cac04049402acac",
      "b89de316a5b24fc69fec285bfee92a5e",
      "27fbc7e5d5de4756b75ea648e18d524b",
      "88e92aec77e8440ab255d0000f7f42d2",
      "241b17e5989c440aa9c8278a9b7411e1",
      "9831f968996e48fbb4daffa39caecbc9",
      "1404e620ab914c19b18d464163955210"
     ]
    },
    "id": "gZ5_PrttgwlZ",
    "outputId": "14df4ae9-6649-4039-8105-f986cf628aaf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50e81dde9e045c089678875b6d16ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55c15326eba49e9a7c0456734a1525b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caefef85532a423aa85d059e816b86be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f2807604444c3abbbaca44ac4ef801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/118 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a323afc9cc4c3e8aa4e186251ea7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27187d656774449ae644e74e256cedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be19782e19544b395dfa6caa2b3c71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ed4008f3d4410cb3e948e4374ea051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00b0fb3ae9942349474cdddaabc4c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45da92c75f9d475080c12cfabdc8b505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/243k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bff3a7d6114175be06b67ccd7fdc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/732k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c68266f5fa4b57a05e9368d8c3d88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e81c46a1244ea18c60e9e3555a2175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating & Collecting: 100%|██████████| 69/69 [20:53<00:00, 18.17s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643b33938a5e446ba8584400ec6440ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ec62bad87b4775841af125557f7478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e76211d207d45b39511fc7111f302a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/235k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1b285566d1459eb172444419b80ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b32dae3d7a4f32af1d97db851f7c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac98b496fe1a47a9a2f482f8db16cceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f97aacd10c04cf7bcea22035d49b3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Finetuned model with r=64 Evaluation Results:\n",
      "    - METEOR: 0.029 (0-1, higher=better)\n",
      "    - BERTScore F1: 0.400 (0-1, higher=better)\n",
      "    - Semantic Similarity: 0.271 (0-1 cosine)\n",
      "    Prompt Alignment:\n",
      "    - Model Responses: 0.254\n",
      "    - Ground Truth: 0.245\n",
      "    - Alignment Ratio: 103.9%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_chat_model(finetuned_model, tokenizer, test_dataloader)\n",
    "\n",
    "print(f\"\"\"\n",
    "    Finetuned model with r=64 alpha=128 Evaluation Results:\n",
    "    - METEOR: {results['meteor']:.3f} (0-1, higher=better)\n",
    "    - BERTScore F1: {results['bertscore_f1']:.3f} (0-1, higher=better)\n",
    "    - Semantic Similarity: {results['semantic_similarity']:.3f} (0-1 cosine)\n",
    "    Prompt Alignment:\n",
    "    - Model Responses: {results['prompt_alignment']['predicted']:.3f}\n",
    "    - Ground Truth: {results['prompt_alignment']['ground_truth']:.3f}\n",
    "    - Alignment Ratio: {results['prompt_alignment']['ratio']:.1%}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551,
     "referenced_widgets": [
      "3a0ac1fb188843a5b18ee861d4e3d92e",
      "b36a8ead2c05473c840cd8a666b77ddf",
      "43c034f54d4b42578ba97bfeaf00f4f3",
      "71018020828f43b1b6d92605a7cb3dd2",
      "2ef72d45526e4d4b907f5ac8f335b248",
      "b8e7d16079a140018689592446c3df55",
      "71addc8ec4af4ae0887669439ccceab6",
      "dff176611c1d4d9faf7b584a67c36d10",
      "7f171f6e16b64d638eb85df8ab308e06",
      "64f18e8b7a75417c9c9361334da65909",
      "b4ef7994bf62409e9aa28e8e983be98f",
      "5241f6913637454bb606a11d5a85e34c",
      "22f44c2bb55c408e9f6eca8945a07114",
      "0bcc030d8a2940ad891f00e094d242e9",
      "f6724824d5bf47e688ad5b590a5bd713",
      "d78b50d1cf134d03b361bc942dd8d691",
      "3e58956a53ea4729950ff30152d117c1",
      "9cdec50c662c403db049a44e4ecc7305",
      "b4f589001a0c439f8a7e9f55caf7ac70",
      "1786bb20002147eaaa142895088bc548",
      "d2bfaa29f4dd4cc4883e1f64c67547e5",
      "c10113c70738459ead5baa43386bc25c",
      "8a8e7db077d34a82a9260c9d4b82012d",
      "d43e9c6122c94d16b78c23e6f87ce5e2",
      "341c1f6e58114b95bf58a05e4afdd58d",
      "df30bf8fb1a34fb19113d9caf9f0fc60",
      "ccd7320f8b614e6ba30efe3944dcb52c",
      "230f09d9bce44608b558cfcc1941c774",
      "b0f1debe1ed4403cb2f4fd78353fc34d",
      "9e217f2dcf4a4bf9a35c108262af2053",
      "803270e44cba4190802a62a19b586772",
      "67dba8f09ce84380a6119708bd99ac4b",
      "14781a11742340f7b3e5f3d008ea12cc",
      "7470e2714c3c4f82bde10a5056bde0b5",
      "a23a821677fa4093b72fdf9d5dab1e75",
      "f3c4f508138c45a08578f09a46ea9d22",
      "4bb079fbaa784081b8df4a2009782c0a",
      "c5c34b27248f4fd397c515c8f9af1ce8",
      "71d85850e5954d1e8af001ba5a82f3c8",
      "3c9bd5bb1d7b48478e42bcad981322fd",
      "264cb3d107814c9f8bb11fa1c63d3d57",
      "adf72e5ee3634b9ea4886f19c900d403",
      "22daa1358b1443ee96046f60450788bd",
      "3f681feaeb6b4d4c88d5b1dcc725b84e",
      "1d11447f4ddd4a939d41ae781c1c839a",
      "2d6d6c2470e9406e9b244dd77d5a568b",
      "a20cbb595e03405691306c242afef5e7",
      "664318c631034183926b0844bb133f39",
      "0b6458d6a1f14f6abef314eed6fa1ede",
      "fba346f4b0244e168af623a43efa48ac",
      "0adb003ca6bd443290de7a46903fc45c",
      "2650bfa8b3ba427d868a1a5acdb216f5",
      "f7159d393bb54b08a7445bfa0e872a72",
      "e760d8a39c6642e89533fb5ee0b60ad7",
      "0b0bcd6376d14f21bfb72e07777d4756",
      "7384bb3907e64e8e907215a5cd3c22fd",
      "44900d18f2bd440c8c9200124ffd994f",
      "0cfd5451b7644ce680da9b727e633e7d",
      "971357591460411f9eaecabb7b5a83d3",
      "853abbddceac4997a89dd72a43002483",
      "0cdbe9d6476340babf9a8c291ba6c92e",
      "d01cfb953f9548cea7c437eefb7188c6",
      "9bd5d465698f4b32bc1230005f845ad3",
      "bd58814cb3f448c6a436d5498b076f8c",
      "afc6348951554ee78f2e283f7d0e4e3e",
      "679da3028e97455e915e2e6b5a8c9c82",
      "dcfa739b9f0543948f291c02d58ef17e",
      "dd69350cf71b45f8992f456bcf9eb731",
      "bd5495dfc6b1411398dcdd2d3f233430",
      "447215edf9f2430a9cb80c3ca2e101b7",
      "efd5a2ad4c3041afb1a805f071e753bb",
      "fa095aef2b9049bdbd3a378b5487de10",
      "ec3d46b3ad074df79a748dbf2033b0c0",
      "634f07b796294c15b650280450be9972",
      "17f5c2bc56bf408c8cf520d01f8a7e63",
      "dd8c0e4c0f9b4768b3246a69bc593937",
      "0a138bc1b8c5461a9b76adb8f2159751"
     ]
    },
    "id": "5iwfanMnvEV0",
    "outputId": "56483799-79e7-4e35-9600-b81133ab0d26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Generating & Collecting: 100%|██████████| 69/69 [14:37<00:00, 12.72s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0ac1fb188843a5b18ee861d4e3d92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5241f6913637454bb606a11d5a85e34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8e7db077d34a82a9260c9d4b82012d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/235k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7470e2714c3c4f82bde10a5056bde0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d11447f4ddd4a939d41ae781c1c839a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7384bb3907e64e8e907215a5cd3c22fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfa739b9f0543948f291c02d58ef17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Finetuned model with r=64 and alpha=64 Evaluation Results:\n",
      "    - METEOR: 0.024 (0-1, higher=better)\n",
      "    - BERTScore F1: 0.411 (0-1, higher=better)\n",
      "    - Semantic Similarity: 0.267 (0-1 cosine)\n",
      "    Prompt Alignment:\n",
      "    - Model Responses: 0.244\n",
      "    - Ground Truth: 0.245\n",
      "    - Alignment Ratio: 99.8%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_chat_model(finetuned_model, tokenizer, test_dataloader)\n",
    "\n",
    "print(f\"\"\"\n",
    "    Finetuned model with r=64 and alpha=64 Evaluation Results:\n",
    "    - METEOR: {results['meteor']:.3f} (0-1, higher=better)\n",
    "    - BERTScore F1: {results['bertscore_f1']:.3f} (0-1, higher=better)\n",
    "    - Semantic Similarity: {results['semantic_similarity']:.3f} (0-1 cosine)\n",
    "    Prompt Alignment:\n",
    "    - Model Responses: {results['prompt_alignment']['predicted']:.3f}\n",
    "    - Ground Truth: {results['prompt_alignment']['ground_truth']:.3f}\n",
    "    - Alignment Ratio: {results['prompt_alignment']['ratio']:.1%}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3KKkxygnf5G"
   },
   "source": [
    "#### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "2a013bd91d6e4e779d5c065c3425243b",
      "dae04dc7952a4923865e1422983556cd",
      "934b0b09ed954f2880bc83f1a172f652",
      "37d1d61bd7694d03b20a490fc9ed413e",
      "01b4697064384b8eac377f141c49ea53",
      "f9e2c5e9a31b467cb695051ae529a2cc",
      "99a92435405e4536ae34b5cb5fff7aa8",
      "1ed1a74d7f2f40d8b0985641150c1f8e",
      "1724b769555844a6b7122c1896d32be2",
      "8255460c035e4b5d9987606b64f1ed77",
      "c814ac3edc304575a4d27242493b36e5",
      "c5e3e24e39014b07a9d54158f9e3f808",
      "440b6ece6ead46e8b1a0f27bbd8aa067",
      "dd7ccf73004e4fce9883ad76435bb74b",
      "c118de227b5d4e9c8cda32107dd0be0b",
      "404bc46139c04109b336060c39b8cd29",
      "b9b8a96d22544ff0a6f38df0849a05a9",
      "d5ca74ba590b4d8894f2d341eb522b19",
      "a3c678a8193747829d85b7ad961f4e06",
      "a2056c7d4f6e4098a8f80f9a08bce73d",
      "99301962b2c84d94a15b55450cb26c52",
      "3fec61ec4aaf4901877300dfba309926",
      "1efa5dff5f3946e3aa364ed9a9bac811",
      "cb9866002b8a4ff392e24135ae341df6",
      "0adf0e029b254a3cbe5ea4d0cc863ed3",
      "3e3c197606ca41068e873b9ee627c48b",
      "8ebb73e0521947e0b3b05799b9f92ebf",
      "ea122f7e4d7c4a8e82be487ee3652a2b",
      "cedaa6de6cec42cf8d7c5ddcbe36b393",
      "ef1fb416911f4b74a191604691736482",
      "223920ade39e4ae19ffec0d0f8f0aec2",
      "97ccf356bb8a40f5ab638ee93c1ae345",
      "759c0395fb91408689bbd62d750f3ad5",
      "d391f26b34ba45d8b3a04ade842d4d82",
      "63405b7dc1de4374a4b97e59e205fdd2",
      "d27376e891514176b3b72f81b24e250d",
      "3219d8fc8dcf4488acb4b3c2cf8f2d99",
      "fddfc088fc9943af92adf0ce7769ba9b",
      "87aecd001545427ba4b7c85565766a64",
      "e3a5efb394d6484badbb43d49bed9edf",
      "40d373b555bd4e668335605ca44850f8",
      "3ea0e5cde6e440e0ab1219b17dc4ca8a",
      "0d6a6a5ed2d94cb39e8d3f0432aa0586",
      "f37be6ebbdad44d9878a1655c18eb2e0",
      "6e0ab34efc3c4eaeba19f1f0caa3f426",
      "9de2ada217ca4feca08ae38d92a9f6ca",
      "c769227cb6f044959b4968945799c4ab",
      "c7f1cfbb055046a09a28c5d607133413",
      "d8bd3d68904e4fe59db3bcfed0f0cb7e",
      "662ab0d16cf24da28a17c601936707d5",
      "364b324362f34df78c1605f7a432d298",
      "1ad90026744440adb00bb4d621bd1457",
      "c8794080010f41bf9c3250770e9aaa49",
      "d876d7a4def34475b7d0fe31d7035db5",
      "330b1b9ade064e94b4b5cfe742679fd0",
      "1cb8e0df60824dab9909f292c5639f6d",
      "b1068ea468254b05b321c339e0dbba87",
      "128f76722a2447069d5be835a79cf619",
      "a24774759a474e10a905151d7924e7b2",
      "a06be1e9108d4d9ab817a23d19afe57f",
      "235357a6e9304a5db215645cd5be5520",
      "7ae2454ae2354ff5b64f2b575fd02962",
      "b4a6871da0d144229ea70ab1d05fb0b5",
      "568c7262d0a7468f97b049bc207a407e",
      "6f43f0ebc6ee467dbdb888d2c0cdf59b",
      "be7a494d166447128cef1a505c98935b",
      "8aa428da09da41e78618447757d46542",
      "289278aa008b4410be39182e7ca6f999",
      "20cbdecb3a36475ca525670146f5d5a3",
      "1f49bfc9dceb46469421a39fe63932e5",
      "f9f34c8a21ed4a32b00a64c9efe30c2d",
      "00ab935eba384835812e412d2a3e7d4e",
      "4f9eae6cb94c48fdb97b2f3833409346",
      "af215b9919f04686aa5f849d27769ac7",
      "93054868bbb440a79dfd8cdde1910f0e",
      "553caab5a5cd495e9be9ce6994bc8413",
      "d406cf53dd7e4991abd930275df9115a"
     ]
    },
    "id": "0Ianxv-rnFG9",
    "outputId": "ccbef90a-20ca-433e-e7ca-22a5b3085fa5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Generating & Collecting: 100%|██████████| 69/69 [18:31<00:00, 16.11s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a013bd91d6e4e779d5c065c3425243b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e3e24e39014b07a9d54158f9e3f808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efa5dff5f3946e3aa364ed9a9bac811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/235k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d391f26b34ba45d8b3a04ade842d4d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0ab34efc3c4eaeba19f1f0caa3f426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb8e0df60824dab9909f292c5639f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa428da09da41e78618447757d46542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Finetuned model with r=64 Evaluation Results:\n",
      "    - METEOR: 0.033 (0-1, higher=better)\n",
      "    - BERTScore F1: 0.414 (0-1, higher=better)\n",
      "    - Semantic Similarity: 0.285 (0-1 cosine)\n",
      "    Prompt Alignment:\n",
      "    - Model Responses: 0.256\n",
      "    - Ground Truth: 0.245\n",
      "    - Alignment Ratio: 104.5%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_chat_model(finetuned_model, tokenizer, test_dataloader)\n",
    "\n",
    "print(f\"\"\"\n",
    "    Finetuned model with r=64 and alpha=32 Evaluation Results:\n",
    "    - METEOR: {results['meteor']:.3f} (0-1, higher=better)\n",
    "    - BERTScore F1: {results['bertscore_f1']:.3f} (0-1, higher=better)\n",
    "    - Semantic Similarity: {results['semantic_similarity']:.3f} (0-1 cosine)\n",
    "    Prompt Alignment:\n",
    "    - Model Responses: {results['prompt_alignment']['predicted']:.3f}\n",
    "    - Ground Truth: {results['prompt_alignment']['ground_truth']:.3f}\n",
    "    - Alignment Ratio: {results['prompt_alignment']['ratio']:.1%}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
